{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing\n",
    "df = pd.read_csv('dataset_space_API_past_launches_raw.csv')\n",
    "\n",
    "\n",
    "# Data Clean\n",
    "df = df.drop(['FlightNumber', 'Date', 'Longitude', 'Latitude'], axis=1) # 删掉没用的\n",
    "\n",
    "\n",
    "# Process missing Value\n",
    "PayloadMass_mean = df['PayloadMass'].mean()\n",
    "PayloadMass_mean = round(PayloadMass_mean, 1)\n",
    "df['PayloadMass'] = df['PayloadMass'].fillna(PayloadMass_mean)\n",
    "df['LandingPad'] = df['LandingPad'].fillna('missing')\n",
    "df['Block'] = df['Block'].fillna('0')\n",
    "\n",
    "\n",
    "# Data Encoding\n",
    "df = df.replace({'Outcome': {'True Ocean': 1, \n",
    "                             'True RTLS': 1,\n",
    "                             'True ASDS': 1,\n",
    "                             'False Ocean':0,\n",
    "                             'False RTLS':0,\n",
    "                             'False ASDS':0,\n",
    "                             'None ASDS':0,\n",
    "                             'None None':0,},\n",
    "                 'GridFins': {True: 1, False: 0},\n",
    "                 'Reused': {True: 1, False: 0},\n",
    "                 'Legs': {True: 1, False: 0}\n",
    "                })\n",
    "\n",
    "dummy_BoosterVersion = pd.get_dummies(df['BoosterVersion'], prefix='BoosterVersion_')\n",
    "dummy_Orbit = pd.get_dummies(df['Orbit'], prefix='Orbit_')\n",
    "dummy_LaunchSite = pd.get_dummies(df['LaunchSite'], prefix='LaunchSite_')\n",
    "dummy_LandingPad = pd.get_dummies(df['LandingPad'], prefix='LandingPad_')\n",
    "dummy_Serial = pd.get_dummies(df['Serial'], prefix='Serial_')\n",
    "\n",
    "df = pd.concat([df, dummy_BoosterVersion, dummy_Orbit, dummy_LaunchSite, dummy_LandingPad, dummy_Serial], axis=1)\n",
    "df = df.drop(['BoosterVersion', 'Orbit', 'LaunchSite', 'LandingPad', 'Serial'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split into training data and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 65 \n",
      "Size of test set: 29\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Outcome'], axis=1)\n",
    "# y = df.drop(df.columns.difference(['Outcome']), axis=1)\n",
    "y = df['Outcome']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=120, shuffle=True)\n",
    "print('Size of train set:', X_train.shape[0], '\\nSize of test set:', X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best hyperparameters for each Classification methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.862\n",
      "Best score: 0.877\n",
      "Best params: {'max_depth': 2, 'max_leaf_nodes': 3, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_dt = {\n",
    "    'max_depth': range(1,5),\n",
    "    'min_samples_leaf': range(1,5),\n",
    "    'min_samples_split': range(2,5),\n",
    "    'max_leaf_nodes': range(2,5)\n",
    "}\n",
    "\n",
    "clf = DecisionTreeClassifier(random_state=120)\n",
    "grid_search = GridSearchCV(estimator=clf, param_grid=param_dt, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Test set score: {:.3f}'.format(grid_search.score(X_test, y_test)))\n",
    "print('Best score: {:.3f}'.format(grid_search.best_score_))\n",
    "print('Best params:', grid_search.best_params_)\n",
    "\n",
    "best_params_dt = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.862\n",
      "Best score on train set: 0.846\n",
      "Best params: {'C': 100, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "param_lr = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "}\n",
    "\n",
    "clf_lr = LogisticRegression(solver = 'liblinear')\n",
    "\n",
    "grid_search = GridSearchCV(estimator = clf_lr, param_grid = param_lr, cv = 5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_params_lr = grid_search.best_params_\n",
    "\n",
    "print('Test set score: {:.3f}'.format(grid_search.score(X_test, y_test)))\n",
    "print('Best score on train set: {:.3f}'.format(grid_search.best_score_))\n",
    "print('Best params:', grid_search.best_params_)\n",
    "\n",
    "best_params_lr = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.655\n",
      "Best score on train set: 0.631\n",
      "Best params: {'C': 10, 'gamma': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "param_svm = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.01, 0.1, 1, 10, 100],\n",
    "}\n",
    "\n",
    "\n",
    "svc = SVC(random_state=140)\n",
    "\n",
    "grid_search = GridSearchCV(estimator=svc, param_grid=param_svm, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print('Test set score: {:.3f}'.format(grid_search.score(X_test, y_test)))\n",
    "print('Best score on train set: {:.3f}'.format(grid_search.best_score_))\n",
    "print('Best params:', grid_search.best_params_)\n",
    "\n",
    "best_params_svm = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.862\n",
      "Best score on train set: 0.877\n",
      "Best params: {'max_depth': 10, 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=150)\n",
    "\n",
    "param_rfc = {'n_estimators': [50, 100, 200],\n",
    "              'max_depth': [5, 10, 20],\n",
    "              'min_samples_split': [2, 5, 10],\n",
    "              'min_samples_leaf': [1, 2, 4]}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=rfc, param_grid=param_rfc, cv=5)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "print('Test set score: {:.3f}'.format(grid_search.score(X_test, y_test)))\n",
    "print('Best score on train set: {:.3f}'.format(grid_search.best_score_))\n",
    "print('Best params:', grid_search.best_params_)\n",
    "\n",
    "best_params_rf = grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find the method performs best using test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n",
      "Confusion Matrix:\n",
      " [[ 8  1]\n",
      " [ 3 17]]\n",
      "Precision: 0.944 \n",
      "Recall: 0.850 \n",
      "F1_score: 0.895\n"
     ]
    }
   ],
   "source": [
    "clf_dt = DecisionTreeClassifier(max_depth = best_params_dt['max_depth'], \n",
    "                               max_leaf_nodes = best_params_dt['max_leaf_nodes'], \n",
    "                             min_samples_leaf = best_params_dt['min_samples_leaf'], \n",
    "                             min_samples_split = best_params_dt['min_samples_split'], \n",
    "                             random_state=120)\n",
    "\n",
    "clf_dt.fit(X_train, y_train)\n",
    "y_pred = clf_dt.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_pred)), \n",
    "      '\\nRecall: {:.3f}'.format(recall_score(y_test, y_pred)), \n",
    "      '\\nF1_score: {:.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n",
      "Confusion Matrix:\n",
      " [[ 9  0]\n",
      " [ 4 16]]\n",
      "Precision: 1.000 \n",
      "Recall: 0.800 \n",
      "F1_score: 0.889\n"
     ]
    }
   ],
   "source": [
    "clf_lr = LogisticRegression(\n",
    "                         max_iter = 100, \n",
    "                         solver = 'liblinear', \n",
    "                         penalty = best_params_lr['penalty'], \n",
    "                         C = best_params_lr['C'])\n",
    "\n",
    "clf_lr.fit(X_train, y_train)\n",
    "y_pred = clf_lr.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_pred)), \n",
    "      '\\nRecall: {:.3f}'.format(recall_score(y_test, y_pred)), \n",
    "      '\\nF1_score: {:.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.828\n",
      "Confusion Matrix:\n",
      " [[ 9  0]\n",
      " [ 5 15]]\n",
      "Precision: 1.000 \n",
      "Recall: 0.750 \n",
      "F1_score: 0.857\n"
     ]
    }
   ],
   "source": [
    "svc = SVC(random_state = 140,\n",
    "          kernel = 'linear',\n",
    "          C = best_params_svm['C'],  \n",
    "          gamma = best_params_svm['gamma'])\n",
    "svc.fit(X_train, y_train)\n",
    "\n",
    "y_pred = svc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_pred)), \n",
    "      '\\nRecall: {:.3f}'.format(recall_score(y_test, y_pred)), \n",
    "      '\\nF1_score: {:.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.862\n",
      "Confusion Matrix:\n",
      " [[ 9  0]\n",
      " [ 4 16]]\n",
      "Precision: 1.000 \n",
      "Recall: 0.800 \n",
      "F1_score: 0.889\n"
     ]
    }
   ],
   "source": [
    "rfc = RandomForestClassifier(n_estimators = best_params_rf['n_estimators'],\n",
    "                             max_depth = best_params_rf['max_depth'],\n",
    "                             min_samples_split = best_params_rf['min_samples_split'],\n",
    "                             min_samples_leaf = best_params_rf['min_samples_leaf'])\n",
    "\n",
    "rfc.fit(X_train, y_train)\n",
    "y_pred = rfc.predict(X_test)\n",
    "\n",
    "print(\"Accuracy: {:.3f}\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print('Precision: {:.3f}'.format(precision_score(y_test, y_pred)), \n",
    "      '\\nRecall: {:.3f}'.format(recall_score(y_test, y_pred)), \n",
    "      '\\nF1_score: {:.3f}'.format(f1_score(y_test, y_pred)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
